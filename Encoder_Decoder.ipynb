{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Decoder "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>ASL Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do you want a ride to the mall?</td>\n",
       "      <td>M-A-L-L RIDE WANT YOU Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes I want to start buying Christmas gifts soon</td>\n",
       "      <td>YES SOON CHRISTMAS GIFTS START BUYING WANT ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please sit in this chair</td>\n",
       "      <td>THIS CHAIR PLEASE SIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I like to fly small planes</td>\n",
       "      <td>SMALL PLANES FLY LIKE ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He will go later</td>\n",
       "      <td>HE GO WILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           English  \\\n",
       "0                  Do you want a ride to the mall?   \n",
       "1  Yes I want to start buying Christmas gifts soon   \n",
       "2                         Please sit in this chair   \n",
       "3                       I like to fly small planes   \n",
       "4                                 He will go later   \n",
       "\n",
       "                                       ASL Gloss  \n",
       "0                        M-A-L-L RIDE WANT YOU Q  \n",
       "1  YES SOON CHRISTMAS GIFTS START BUYING WANT ME  \n",
       "2                          THIS CHAIR PLEASE SIT  \n",
       "3                       SMALL PLANES FLY LIKE ME  \n",
       "4                                     HE GO WILL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ASL_English.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18\n",
       "Name: ASL Gloss, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG/Mode in ASL Gloss \n",
    "# 18 characters\n",
    "df['ASL Gloss'].str.len().mode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Note:\n",
    "- Replace the numbers/digits\n",
    "- Check regarding Finger spellings\n",
    "- Check if it is required to add start and end tokens to target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "df['English'] = df['English'].apply(lambda x: x.strip())\n",
    "df['ASL Gloss'] = df['ASL Gloss'].apply(lambda x: x.strip())\n",
    "\n",
    "# Lowercase all characters\n",
    "df['English'] = df['English'].apply(lambda x: x.lower())\n",
    "df['ASL Gloss'] = df['ASL Gloss'].apply (lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes # Might not need this\n",
    "# df['English'] = df['English'].apply(lambda x: re.sub (r\"'\", '', x))\n",
    "# df['ASL Gloss'] = df['ASL Gloss'].apply(lambda x: re.sub (r\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all special character\n",
    "df['English'] = df['English'].apply(lambda x: ' '.join (ch for ch in x if ch not in set(string.punctuation)))\n",
    "df['ASL Gloss'] = df['ASL Gloss'].apply(lambda x: ' '.join (ch for ch in x if ch not in set(string.punctuation)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace them later** and remove all numbers/digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset has numbers\n",
    "print(df['English'].str.contains(r'\\d').any())\n",
    "print(df['ASL Gloss'].str.contains(r'\\d').any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one-seven-one A-N-Y-W-H-E-R-E L-A-N-E nine-eight-seven-six-five'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacements = {'1': \"one\", '2':\"two\", '3':\"three\", '4':\"four\", '5':\"five\", '6':\"six\", '7':\"seven\", '8':\"eight\", '9':\"nine\", '0':\"zero\"}\n",
    "df['English'] = df['English'].apply(lambda x: re.sub('(\\d)', lambda m: replacements[m.group()], x))\n",
    "df['ASL Gloss'] = df['ASL Gloss'].apply(lambda x: re.sub('(\\d)', lambda m: replacements[m.group()], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            START_ Do you want a ride to the mall? _END\n",
       "1      START_ Yes I want to start buying Christmas gi...\n",
       "2                   START_ Please sit in this chair _END\n",
       "3                 START_ I like to fly small planes _END\n",
       "4                           START_ He will go later _END\n",
       "                             ...                        \n",
       "272                    START_ Sit in the wheelchair _END\n",
       "273                        START_ You have a sprain _END\n",
       "274          START_ You need to get to the hospital _END\n",
       "275            START_ Im dizzy and my stomach hurts _END\n",
       "276                        START_ Well go to the ER _END\n",
       "Name: English, Length: 277, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add tokens to target sequence\n",
    "df['English'] = df['English'].apply(lambda x : 'START_ ' + x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get English and ASL Vocabulary\n",
    "all_eng_words = set()\n",
    "\n",
    "for eng in df ['English'] :\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_ASL_words = set()\n",
    "\n",
    "for asl in df ['ASL Gloss'] :\n",
    "    for word in asl.split():\n",
    "        if word not in all_ASL_words:\n",
    "            all_ASL_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Words: 575\n",
      "ASL Words: 478\n"
     ]
    }
   ],
   "source": [
    "print(\"English Words:\", len(all_eng_words))\n",
    "print(\"ASL Words:\", len(all_ASL_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 575)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_ASL_words))\n",
    "target_words = sorted(list(all_eng_words) )\n",
    "num_encoder_tokens = len(all_ASL_words)\n",
    "num_decoder_tokens = len(all_eng_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m latent_dim \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Encoder\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m encoder_inputs \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m, ) )\n\u001b[0;32m      7\u001b[0m enc_emb \u001b[39m=\u001b[39m Embedding(num_encoder_tokens, latent_dim, mask_zero \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) (encoder_inputs)\n\u001b[0;32m      8\u001b[0m encoder_lstm \u001b[39m=\u001b[39m LSTM(latent_dim, return_state\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "\n",
    "latent_dim = 64\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None, ) )\n",
    "enc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero = True) (encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# Discard 'encoder outputs' and only keep the states.\n",
    "encoder_states = [state_h, state_c ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using 'encoder states' as initial state.\n",
    "decoder inputs Input (shape= (None, ) )\n",
    "dec emb layer = Embedding (num decoder tokens, latent dim, mask zero True)\n",
    "dec emb = dec emb layer (decoder inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder 1 stm = LSTM (latent dim, return sequences—Truet return state—True)\n",
    "decoder outputs,\n",
    "= decoder 1 stm (dec em-b,\n",
    "initial state—encoder states)\n",
    "decoder dense = Dense (num decoder tokens, activation—' softmax' )\n",
    "decoder outputs decoder dense (decoder outputs)\n",
    "# Define the model that will turn\n",
    "# s encoder input data' s 'decoder input datas into 'decoder target data\n",
    "model Model ( [encoder inputs, decoder inputs] , decoder outputs)\n",
    "model. compile (optimizer—' rmsprop', loss—' categorical crossentropy' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GradProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edb0346f0263be255e9bd43b772a6cfa08359fe534328d5e302e6f0d415052f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
