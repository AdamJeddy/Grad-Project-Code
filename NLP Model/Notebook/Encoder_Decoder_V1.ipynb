{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Decoder "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>ASL Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do you want a ride to the mall?</td>\n",
       "      <td>M-A-L-L RIDE WANT YOU Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes I want to start buying Christmas gifts soon</td>\n",
       "      <td>YES SOON CHRISTMAS GIFTS START BUYING WANT ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please sit in this chair</td>\n",
       "      <td>THIS CHAIR PLEASE SIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I like to fly small planes</td>\n",
       "      <td>SMALL PLANES FLY LIKE ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He will go later</td>\n",
       "      <td>HE GO WILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           English  \\\n",
       "0                  Do you want a ride to the mall?   \n",
       "1  Yes I want to start buying Christmas gifts soon   \n",
       "2                         Please sit in this chair   \n",
       "3                       I like to fly small planes   \n",
       "4                                 He will go later   \n",
       "\n",
       "                                       ASL Gloss  \n",
       "0                        M-A-L-L RIDE WANT YOU Q  \n",
       "1  YES SOON CHRISTMAS GIFTS START BUYING WANT ME  \n",
       "2                          THIS CHAIR PLEASE SIT  \n",
       "3                       SMALL PLANES FLY LIKE ME  \n",
       "4                                     HE GO WILL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ASL_English.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1670, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG/Mode in ASL Gloss \n",
    "# 18 characters\n",
    "df['ASL Gloss'].str.len().mode()\n",
    "\n",
    "# Max \n",
    "df['ASL Gloss'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG/Mode in English\n",
    "# 22 characters\n",
    "df['English'].str.len().mode()\n",
    "\n",
    "# Max\n",
    "df['English'].str.len().max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Note:\n",
    "- Replace the numbers/digits\n",
    "- Check regarding Finger spellings\n",
    "- Check if it is required to add start and end tokens to target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {'1': \"one \", '2':\"two \", '3':\"three \", '4':\"four \", '5':\"five \", '6':\"six \", '7':\"seven \", '8':\"eight \", '9':\"nine \", '0':\"zero \"}\n",
    "df['English'] = df['English'].apply(lambda x: re.sub('(\\d)', lambda m: replacements[m.group()], x))\n",
    "df['ASL Gloss'] = df['ASL Gloss'].apply(lambda x: re.sub('(\\d)', lambda m: replacements[m.group()], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "df['English'] = df['English'].apply(lambda x: x.strip())\n",
    "df['ASL Gloss'] = df['ASL Gloss'].apply(lambda x: x.strip())\n",
    "\n",
    "# Lowercase all characters\n",
    "df['English'] = df['English'].apply(lambda x: x.lower())\n",
    "df['ASL Gloss'] = df['ASL Gloss'].apply (lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['English'] = df['English'].apply(lambda x: x.replace('  ', ' '))\n",
    "df['ASL Gloss'] = df['ASL Gloss'].apply(lambda x: x.replace('  ', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>ASL Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do you want a ride to the mall?</td>\n",
       "      <td>m-a-l-l ride want you q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes i want to start buying christmas gifts soon</td>\n",
       "      <td>yes soon christmas gifts start buying want me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please sit in this chair</td>\n",
       "      <td>this chair please sit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i like to fly small planes</td>\n",
       "      <td>small planes fly like me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he will go later</td>\n",
       "      <td>he go will</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           English  \\\n",
       "0                  do you want a ride to the mall?   \n",
       "1  yes i want to start buying christmas gifts soon   \n",
       "2                         please sit in this chair   \n",
       "3                       i like to fly small planes   \n",
       "4                                 he will go later   \n",
       "\n",
       "                                       ASL Gloss  \n",
       "0                        m-a-l-l ride want you q  \n",
       "1  yes soon christmas gifts start buying want me  \n",
       "2                          this chair please sit  \n",
       "3                       small planes fly like me  \n",
       "4                                     he go will  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes # Might not need this\n",
    "# df['English'] = df['English'].apply(lambda x: re.sub (r\"'\", '', x))\n",
    "# df['ASL Gloss'] = df['ASL Gloss'].apply(lambda x: re.sub (r\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all special character\n",
    "df['English'] = df['English'].apply(lambda x: ''.join (ch for ch in x if ch not in set(string.punctuation)))\n",
    "df['ASL Gloss'] = df['ASL Gloss'].apply(lambda x: ''.join (ch for ch in x if ch not in set(string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>ASL Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do you want a ride to the mall</td>\n",
       "      <td>mall ride want you q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes i want to start buying christmas gifts soon</td>\n",
       "      <td>yes soon christmas gifts start buying want me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please sit in this chair</td>\n",
       "      <td>this chair please sit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i like to fly small planes</td>\n",
       "      <td>small planes fly like me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he will go later</td>\n",
       "      <td>he go will</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           English  \\\n",
       "0                   do you want a ride to the mall   \n",
       "1  yes i want to start buying christmas gifts soon   \n",
       "2                         please sit in this chair   \n",
       "3                       i like to fly small planes   \n",
       "4                                 he will go later   \n",
       "\n",
       "                                       ASL Gloss  \n",
       "0                           mall ride want you q  \n",
       "1  yes soon christmas gifts start buying want me  \n",
       "2                          this chair please sit  \n",
       "3                       small planes fly like me  \n",
       "4                                     he go will  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace them later** and remove all numbers/digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset has numbers\n",
    "print(df['English'].str.contains(r'\\d').any())\n",
    "print(df['ASL Gloss'].str.contains(r'\\d').any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tokens to target sequence\n",
    "df['English'] = df['English'].apply(lambda x : 'START_ ' + x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>ASL Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>START_ do you want a ride to the mall _END</td>\n",
       "      <td>mall ride want you q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>START_ yes i want to start buying christmas gi...</td>\n",
       "      <td>yes soon christmas gifts start buying want me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>START_ please sit in this chair _END</td>\n",
       "      <td>this chair please sit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>START_ i like to fly small planes _END</td>\n",
       "      <td>small planes fly like me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>START_ he will go later _END</td>\n",
       "      <td>he go will</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0         START_ do you want a ride to the mall _END   \n",
       "1  START_ yes i want to start buying christmas gi...   \n",
       "2               START_ please sit in this chair _END   \n",
       "3             START_ i like to fly small planes _END   \n",
       "4                       START_ he will go later _END   \n",
       "\n",
       "                                       ASL Gloss  \n",
       "0                           mall ride want you q  \n",
       "1  yes soon christmas gifts start buying want me  \n",
       "2                          this chair please sit  \n",
       "3                       small planes fly like me  \n",
       "4                                     he go will  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455    108\n",
       "558    105\n",
       "918    104\n",
       "712    104\n",
       "531    103\n",
       "Name: ASL Gloss, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ASL Gloss'].str.len().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632    144\n",
       "921    130\n",
       "455    125\n",
       "918    118\n",
       "285    117\n",
       "Name: English, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['English'].str.len().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get English and ASL Vocabulary\n",
    "all_eng_words = set()\n",
    "\n",
    "for eng in df ['English'] :\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_ASL_words = set()\n",
    "\n",
    "for asl in df ['ASL Gloss'] :\n",
    "    for word in asl.split():\n",
    "        if word not in all_ASL_words:\n",
    "            all_ASL_words.add(word)\n",
    "\n",
    "#max_length_src = 45\n",
    "#max_length_tar = 53\n",
    "#max_length_src = 108\n",
    "#max_length_tar = 144\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length target:  25\n",
      "Max length sorce:  18\n",
      "Encoder token: 1947\n",
      "Decoder token: 2002\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary of English\n",
    "all_eng_words = set()\n",
    "for eng in df['English']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "# Vocabulary of ASL \n",
    "all_ASL_words = set()\n",
    "for asl in df['ASL Gloss']:\n",
    "    for word in asl.split():\n",
    "        if word not in all_ASL_words:\n",
    "            all_ASL_words.add(word)\n",
    "\n",
    "# Max Length of source sequence\n",
    "lenght_list=[]\n",
    "for l in df ['English']:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "print(\"Max length target: \", max_length_tar)\n",
    "\n",
    "# Max Length of target sequence\n",
    "lenght_list=[]\n",
    "for l in df ['ASL Gloss']:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "print(\"Max length sorce: \", max_length_src)\n",
    "\n",
    "input_words = sorted(list(all_ASL_words))\n",
    "target_words = sorted(list(all_eng_words))\n",
    "\n",
    "# Calculate Vocab size for both source and target\n",
    "num_encoder_tokens = len(all_ASL_words)\n",
    "num_decoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens += 1 # For zero padding\n",
    "print(\"Encoder token:\", num_encoder_tokens)\n",
    "print(\"Decoder token:\", num_decoder_tokens)\n",
    "\n",
    "# Create word to token dictionary for both source and target\n",
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "# Create token to word dictionary for both source and target\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Words: 2001\n",
      "ASL Words: 1947\n"
     ]
    }
   ],
   "source": [
    "print(\"English Words:\", len(all_eng_words))\n",
    "print(\"ASL Words:\", len(all_ASL_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1947, 2001)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_ASL_words))\n",
    "target_words = sorted(list(all_eng_words))\n",
    "num_encoder_tokens = len(all_ASL_words)\n",
    "num_decoder_tokens = len(all_eng_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n"
     ]
    }
   ],
   "source": [
    "num_decoder_tokens += 1\n",
    "print (num_decoder_tokens)\n",
    "\n",
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1586,), (84,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = df['ASL Gloss'], df['English']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.05)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "\n",
    "latent_dim = 64\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None, ) )\n",
    "enc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero = True) (encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# Discard 'encoder outputs' and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "# Set up the decoder, using 'encoder states' as initial state.\n",
    "decoder_inputs = Input(shape= (None, ) )\n",
    "dec_emb_layer = Embedding (num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer (decoder_inputs)\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM (latent_dim, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,initial_state = encoder_states)\n",
    "decoder_dense = Dense (num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# 'encoder input data' & 'decoder input datas into 'decoder target data'\n",
    "model = Model([encoder_inputs, decoder_inputs] , decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model (encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "#Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input (shape= (latent_dim, ))\n",
    "decoder_state_input_c = Input (shape= (latent_dim, ))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer (decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "#To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm (dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense (decoder_outputs2) # A dense softmax layer to generate prob dist. over the target voc\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence (input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict (input_seq)\n",
    "    \n",
    "    #Generate empty target sequence of length 1.\n",
    "    target_seq= np.zeros ( (1,1))\n",
    "\n",
    "    # Popula te the first cha ra cter of target sequence with the start chara cter.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict ([target_seq] + states_value)\n",
    "        \n",
    "        # Sample a token\n",
    "        sampled_token_index= np.argmax (output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index [sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "        \n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == \"_END\" or len(decoded_sentence) > 50):\n",
    "                stop_condition = True\n",
    "        \n",
    "        #Update the target sequence (of length 1) .\n",
    "        target_seq= np.zeros ((1,1))\n",
    "        target_seq [0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch (X = x_train, y = y_train, batch_size= 128):\n",
    "    '''Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range (0, len (X), batch_size) :\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n",
    "            decoder_input_data = np.zeros ( (batch_size, max_length_tar), dtype='float32')\n",
    "            decoder_target_data = np.zeros ( (batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate (zip (X.iloc[j:j+batch_size], y.iloc[j:j+batch_size])):\n",
    "                for t, word in enumerate (input_text.split ()):\n",
    "                    encoder_input_data [i, t] = input_token_index [word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split ()) :\n",
    "                    if t > len(target_text.split ()) - 1:\n",
    "                        decoder_input_data [i, t] = target_token_index [word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START token\n",
    "                        # offset by one timestep\n",
    "                        decoder_target_data [i, t - 1, target_token_index [word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(x_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Input ASL_sentence: weather today what sunny\n",
      "Actual English Translation: today the weather is sunny\n",
      "Predicted English Translation:  boston george boston george gymnastics\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input ASL_sentence:', x_train.iloc[k: k+1].values[0])\n",
    "print('Actual English Translation:', y_train.iloc[k: k+1].values[0][7:-5])\n",
    "print('Predicted English Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Input ASL_sentence: which state you from\n",
      "Actual English Translation: which state are you from\n",
      "Predicted English Translation:  hamburgers smells dollars tend\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input ASL_sentence:', x_train.iloc[k: k+1].values[0])\n",
    "print('Actual English Translation:', y_train.iloc[k: k+1].values[0][7:-5])\n",
    "print('Predicted English Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Input ASL_sentence: good deals my brother always find why he thrifty\n",
      "Actual English Translation: my brother always finds good deals because he is thrifty\n",
      "Predicted English Translation:  grocery grocery watermelon monday\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input ASL_sentence:', x_train.iloc[k: k+1].values[0])\n",
    "print('Actual English Translation:', y_train.iloc[k: k+1].values[0][7:-5])\n",
    "print('Predicted English Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17069188d88b1100ef242ce351d44cf343932479c7edb3acc83f5a4d63d17234"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
